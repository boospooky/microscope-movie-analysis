{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named bokeh.plotting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1ff490086ac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_as_ubyte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moutput_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpalettes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named bokeh.plotting"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import multiprocessing\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# rc={'lines.linewidth': 2, 'axes.labelsize': 14, 'axes.titlesize': 14}\n",
    "\n",
    "# sns.set(rc=rc)\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "import scipy as scp\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.animation as anm\n",
    "from IPython.display import HTML\n",
    "\n",
    "from skimage.external.tifffile import TiffWriter\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import skimage.filters\n",
    "import skimage.io\n",
    "import skimage.morphology\n",
    "import skimage.feature\n",
    "import skimage.exposure\n",
    "\n",
    "from skimage import data, color\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from skimage.draw import circle_perimeter\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh import palettes, transform\n",
    "\n",
    "rc = {'lines.linewidth': 2, \n",
    "      'axes.labelsize': 18, \n",
    "      'axes.titlesize': 24, \n",
    "      'xtick.labelsize': 18, \n",
    "      'ytick.labelsize': 18, \n",
    "      'legend.fontsize': 18,\n",
    "      'axes.facecolor': 'fbfbfc'}\n",
    "sns.set_context('talk', rc=rc)\n",
    "\n",
    "%matplotlib inline\n",
    "output_notebook()\n",
    "\n",
    "# you need to populate image lists from the two folders\n",
    "\n",
    "# file_temp = \"/mnt/disks/movie-181208/180827_1/{}/img_{:09d}_{}_000.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Channel information for IX81 inverted microscope\n",
    "all_channel_inds = [str(xx) for xx in range(6)]\n",
    "all_channel_names = ['Brightfield', 'GFP', 'YFP', 'mScarlet', 'unk', 'sfCFP']\n",
    "all_channel_dict = dict(zip(all_channel_inds, all_channel_names))\n",
    "\n",
    "def img_metadata_dict(img):\n",
    "    '''Read metadata into dictionary from the TIFF metadata. \n",
    "    \n",
    "        This function uses string replacements to read dictionary key-value pairs.\n",
    "    \n",
    "    '''\n",
    "    metadata_key = 50839\n",
    "    metadata_str = img.tag[metadata_key].decode('utf-8').replace(\"\\x00\",\"\")\n",
    "    splits = re.split(\",\",metadata_str)\n",
    "    metadata_keys = []\n",
    "    metadata_vals = []\n",
    "    for split_x in splits:\n",
    "        hits = re.findall(r\"(?<=\\\").*?(?=\\\")\", split_x)\n",
    "        if len(hits) == 3:\n",
    "            key, _, val = [hit.replace(\"'\",\"\").strip() for hit in hits]\n",
    "            metadata_keys.append(key)\n",
    "            metadata_vals.append(val)\n",
    "    return dict(zip(metadata_keys, metadata_vals))\n",
    "\n",
    "def img_metadata_dict_full(img):\n",
    "    '''Read metadata into dictionary from the TIFF metadata. \n",
    "    \n",
    "        After some cleanup, this function reads the metadata string directly as a dictionary definition.\n",
    "    '''\n",
    "    metadata_key = 50839\n",
    "    metadata_str = img.tag[metadata_key].decode('utf-8').replace(\"\\x00\",\"\")\n",
    "    in_str = metadata_str[9:].replace('\\n','').replace('\\s*','').replace('null','None').replace('false','True')\n",
    "    out_dict = ast.literal_eval(in_str)\n",
    "    return out_dict\n",
    "\n",
    "def img_metadata(img):\n",
    "    '''Read creation time from the TIFF metadata in seconds from Epoch'''\n",
    "    metadata = img_metadata_dict(img)\n",
    "    time_tuple = time.strptime(metadata['Time'],r\"%Y-%m-%d %H:%M:%S %z\")\n",
    "    return time.mktime(time_tuple), metadata[\"Channel\"]\n",
    "\n",
    "def fn_metadata(fn):\n",
    "    '''Wrapper for reading creation time from an image filename'''\n",
    "    with Image.open(fn) as img:\n",
    "        out = img_metadata(img)\n",
    "    return out\n",
    "\n",
    "def fn_metadata_full(fn):\n",
    "    '''Wrapper for reading full metadata dictionary from a filename'''\n",
    "    with Image.open(fn) as img:\n",
    "        out = img_metadata_dict_full(img)\n",
    "    return out\n",
    "\n",
    "def get_time_vector_from_fn(fn):\n",
    "    time_dict = dict(zip(channel,len(channel)*[]))\n",
    "    with Image.open(fn) as img:\n",
    "        try:\n",
    "            while 1:\n",
    "                ct, ch = img_metadata(img)\n",
    "                time_dict[chan_dict[ch]].append(ct)\n",
    "                img.seek(img.tell()+1)\n",
    "        except EOFError:\n",
    "            pass\n",
    "        except ValueError:\n",
    "            pass\n",
    "        except SyntaxError:\n",
    "            pass\n",
    "    return time_dict\n",
    "\n",
    "def get_data_from_frame(img):\n",
    "    ct, ch = img_metadata(img)\n",
    "    im_arr = np.array(list(img.getdata()),dtype=np.uint16).reshape(img.size[::-1])\n",
    "    return ct, ch, im_arr\n",
    "\n",
    "def get_movie_from_img(img):\n",
    "    img_dict = dict(zip(channel,len(channel)*[]))\n",
    "    time_dict = dict(zip(channel,len(channel)*[]))\n",
    "    try:\n",
    "        img.seek(0)\n",
    "        while 1:\n",
    "            ct, ch, im_arr = get_data_from_frame(img)\n",
    "            ch = chan_dict[ch]\n",
    "            img_dict[ch].append(im_arr)\n",
    "            time_dict[ch].append(ct)\n",
    "            img.seek(img.tell()+1)\n",
    "    except EOFError:\n",
    "        pass\n",
    "    except ValueError:\n",
    "        pass\n",
    "    except SyntaxError:\n",
    "        pass\n",
    "    for key in img_dict:\n",
    "        h, w = im_arr.shape\n",
    "        img_dict[key] = np.vstack([x.reshape((1, h, w, 1)) for x in img_dict[key]])\n",
    "    return img_dict, time_dict\n",
    "\n",
    "def read_img(fn):\n",
    "    with Image.open(fn) as img:\n",
    "        return get_movie_from_img(img)\n",
    "        \n",
    "def concat_img_files(fn_list, fn_out):\n",
    "    keep_keys = ['Channel', 'Time', 'PositionName']\n",
    "    metadata = dict(zip(keep_keys, keep_keys))\n",
    "    i = 0\n",
    "    #ct = datetime.datetime.fromtimestamp(ctime(fn))\n",
    "    with TiffWriter(fn_out, bigtiff=True) as tif:\n",
    "        for fn in fn_list:\n",
    "            eof_flag = True\n",
    "            print(\"Writing \", fn)\n",
    "            with Image.open(fn) as img:\n",
    "                while eof_flag:\n",
    "                    _, _, im_arr = get_data_from_frame(img)\n",
    "                    img_md = img_metadata_dict(img)\n",
    "                    for k in keep_keys:\n",
    "                        metadata[k] = img_md[k]\n",
    "                    metadata['Frame'] = int(os.path.basename(fn).split(\"_\")[1])\n",
    "                    h, w = im_arr.shape\n",
    "                    tif.save(im_arr, metadata=metadata.copy())\n",
    "                    try:\n",
    "                        i += 1\n",
    "                        img.seek(img.tell()+1)\n",
    "                    except:\n",
    "                        eof_flag = False\n",
    "        \n",
    "def convert_img_file(fn, fn_out):\n",
    "    dirname = os.path.dirname(fn)\n",
    "    fn_out = os.path.join(dirname, fn_out)\n",
    "    ct = datetime.datetime.fromtimestamp(ctime(fn))\n",
    "    eof_flag = True\n",
    "    with Image.open(fn) as img:\n",
    "        with TiffWriter(fn_out, bigtiff=True) as tif:\n",
    "            while eof_flag:\n",
    "                _, _, im_arr = get_data_from_frame(img)\n",
    "                metadata = img_metadata_dict(img)\n",
    "                tif.save(im_arr, datetime=ct, metadata=metadata)\n",
    "                try:\n",
    "                    img.seek(img.tell()+1)\n",
    "                except:\n",
    "                    eof_flag = False\n",
    "    \n",
    "def process_file(fn, skip=0):\n",
    "    with Image.open(fn) as img:\n",
    "        eof_flag = True\n",
    "        column_names = ('time', 'colony', 'sfcfp', 'mscarlet', 'col_size', 'sfcfp_bg', 'mscarlet_bg')\n",
    "        df = pd.DataFrame(columns = column_names)\n",
    "        try:\n",
    "            while eof_flag:\n",
    "                acq_dict = {}\n",
    "                for i in range(3):\n",
    "                    ct, ch, im_arr = get_data_from_frame(img)\n",
    "#                     ch = chan_dict[ch]\n",
    "                    acq_dict[ch] = (ct, im_arr)\n",
    "                    try:\n",
    "                        img.seek(img.tell()+1)\n",
    "                    except EOFError:\n",
    "                        eof_flag = False\n",
    "                rfps, cfps, sizes, num, cfp_bg, rfp_bg = get_fluors(acq_dict['3'][1], acq_dict['5'][1], acq_dict['0'][1])\n",
    "                for col_i in range(num):\n",
    "                    df_dict = dict(zip(column_names, [[ct], [col_i], [cfps[col_i]], [rfps[col_i]], [sizes[col_i]], [cfp_bg], [rfp_bg]]))\n",
    "                    df = df.append(pd.DataFrame(df_dict), ignore_index=True)\n",
    "                try:\n",
    "                    img.seek(img.tell()+3*skip)\n",
    "                except EOFError:\n",
    "                    eof_flag = False\n",
    "        except EOFError:\n",
    "            pass\n",
    "        except ValueError:\n",
    "            pass\n",
    "        except SyntaxError:\n",
    "            pass\n",
    "        df.to_csv(fn+\".csv\")\n",
    "    return df\n",
    "\n",
    "    \n",
    "def process_file_skimage(fn):\n",
    "    time_vec = get_time_vector_from_fn(fn)['\"Brightfield\"']\n",
    "    im = skimage.io.imread(fn)\n",
    "    column_names = ('time', 'colony', 'sfcfp', 'mscarlet', 'col_size', 'sfcfp_bg', 'mscarlet_bg')\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "    try:\n",
    "        while eof_flag:\n",
    "            acq_dict = {}\n",
    "            for i in range(3):\n",
    "                ct, ch, im_arr = get_data_from_frame(img)\n",
    "                acq_dict[ch] = (ct, im_arr)\n",
    "                try:\n",
    "                    img.seek(img.tell()+1)\n",
    "                except EOFError:\n",
    "                    eof_flag = False\n",
    "            rfps, cfps, sizes, num, cfp_bg, rfp_bg = get_fluors(acq_dict['3'][1], acq_dict['5'][1], acq_dict['0'][1])\n",
    "            for col_i in range(num):\n",
    "                df_dict = dict(zip(column_names, [[ct], [col_i], [cfps[col_i]], [rfps[col_i]], [sizes[col_i]], [cfp_bg], [rfp_bg]]))\n",
    "                df = df.append(pd.DataFrame(df_dict), ignore_index=True)\n",
    "    except EOFError:\n",
    "        pass\n",
    "    except ValueError:\n",
    "        pass\n",
    "    except SyntaxError:\n",
    "        pass\n",
    "    except KeyError:\n",
    "        pass\n",
    "    df.to_csv(fn+\".csv\")\n",
    "    return df\n",
    "\n",
    "def ctime(fname):\n",
    "    '''Read creation time from the TIFF metadata in seconds from Epoch'''\n",
    "    metadata_key = 50839\n",
    "    with Image.open(fname) as img:\n",
    "        metadata_str = img.tag_v2[50839].decode('utf-8').replace(\"\\x00\",\"\")\n",
    "    splits = re.split(\",\",metadata_str)\n",
    "    metadata_keys = []\n",
    "    metadata_vals = []\n",
    "    for split_x in splits:\n",
    "        hits = re.findall(r\"(?<=\\\").*?(?=\\\")\", split_x)\n",
    "        if len(hits) == 3:\n",
    "            key, _, val = [hit.replace(\"'\",\"\").strip() for hit in hits]\n",
    "            metadata_keys.append(key)\n",
    "            metadata_vals.append(val)\n",
    "    metadata = dict(zip(metadata_keys, metadata_vals))\n",
    "\n",
    "    time_tuple = time.strptime(metadata['Time'][:-6],r\"%Y-%m-%d %H:%M:%S\")\n",
    "    return time.mktime(time_tuple)\n",
    "\n",
    "def crop(img):\n",
    "    w, h = img.shape\n",
    "    if w > 1000:\n",
    "        x1, x2, y1, y2 = np.array((80, 650 ,20, 550))*2\n",
    "    else:\n",
    "        x1, x2, y1, y2 = np.array((80, 650 ,20, 550))\n",
    "    return(img[y1:y2,x1:x2])\n",
    "\n",
    "def uncrop(img):\n",
    "    w, h = img.shape\n",
    "    if w > 800:\n",
    "        out_img = np.zeros((512*2, 672*2))\n",
    "        x1, x2, y1, y2 = np.array((80, 650 ,20, 550))*2\n",
    "    else:\n",
    "        out_img = np.zeros((512, 672))\n",
    "        x1, x2, y1, y2 = np.array((80, 650 ,20, 550))\n",
    "    out_img[y1:y2,x1:x2] = img\n",
    "    return(out_img)\n",
    "\n",
    "def label_image(im_arr):\n",
    "    im_arr = im_arr.astype(np.float32).astype(np.uint16) / 65535\n",
    "    w, h = im_arr.shape\n",
    "\n",
    "    # Convert the uneven image to floating point\n",
    "    im_float = im_arr\n",
    "    # Smooth to reduce noise\n",
    "    g_radius = 5\n",
    "    im_smooth = skimage.filters.gaussian(im_float, g_radius)\n",
    "    im_bgsub = im_float - im_smooth\n",
    "\n",
    "    # Perform the median filter\n",
    "    selem = skimage.morphology.square(4)\n",
    "    im_bgsub = skimage.filters.median(im_bgsub, selem) / 4096.0\n",
    "    \n",
    "    # Adjust exposure\n",
    "    im_adj = skimage.exposure.equalize_adapthist(im_bgsub)\n",
    "\n",
    "    # Edge detection\n",
    "    im_edge = skimage.filters.sobel(im_adj)\n",
    "    im_edge = skimage.exposure.equalize_adapthist(im_adj)\n",
    "\n",
    "    # Remove small objects and fill holes\n",
    "    if np.all(im_edge == im_edge[0,0]) or np.any(np.isnan(im_edge)):\n",
    "        return np.zeros((w,h)), 1\n",
    "    thresh = skimage.filters.threshold_otsu(im_edge)\n",
    "    selem = skimage.morphology.square(2)\n",
    "    im_bw = skimage.morphology.binary_dilation(im_edge > thresh, selem)\n",
    "    selem = skimage.morphology.square(12)\n",
    "    im_bw = skimage.morphology.binary_closing(im_bw, selem)\n",
    "    \n",
    "    im_bw = skimage.morphology.remove_small_objects(im_bw, min_size=10)\n",
    "    im_labeled, num = skimage.morphology.label(im_bw, return_num=True)\n",
    "    return im_labeled, num\n",
    "\n",
    "def get_fluors(bfi, rfp, gfp):\n",
    "    im_labeled, num = label_image_2(bfi)\n",
    "    num  = im_labeled.max()\n",
    "#     rfp, gfp = [crop(x) for x in [rfp, gfp]]\n",
    "    gfps = [np.mean(gfp[im_labeled == x]) for x in np.arange(1,num+1)]\n",
    "    rfps = [np.mean(rfp[im_labeled == x]) for x in np.arange(1,num+1)]\n",
    "    gfp_bg = np.mean(gfp[im_labeled == 0])\n",
    "    rfp_bg = np.mean(rfp[im_labeled == 0])\n",
    "    sizes = [np.sum(im_labeled == x) for x in np.arange(1,num+1)]\n",
    "    return rfps, gfps, sizes, num, gfp_bg, rfp_bg\n",
    "\n",
    "def read_tiff_file(fn, skip=0):\n",
    "    print(\"Begin \" + fn)\n",
    "    df = process_file(fn, skip=skip)\n",
    "    df.to_csv(fn+\".csv\", index=False)\n",
    "    print(\"Finished \" + fn)\n",
    "\n",
    "def par_worker(fn_list, skip=1):\n",
    "    for fn in fn_list:\n",
    "        read_tiff_file(fn, skip=skip)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "super_dir = '/mnt/disks/timelapse-movies/190108/data'\n",
    "exp_dirs = [os.path.join(super_dir, xx) for xx in os.listdir(super_dir)]\n",
    "pos_dirs = [os.path.join(exp_dir, xx) for exp_dir in exp_dirs for xx in os.listdir(exp_dir) if 'Pos' in xx]\n",
    "img_files = []\n",
    "pos_vec = []\n",
    "frame_vec = []\n",
    "channel_vec = []\n",
    "time_vec = []\n",
    "for pos_dir in pos_dirs:\n",
    "    tmp_dir, pos_str = pos_dir.split('Pos')\n",
    "    pos_int = np.int(pos_str)\n",
    "    tmp_img_files = [xx for xx in os.listdir(pos_dir) if '.tif' in xx]\n",
    "    img_files.extend([os.path.join(tmp_dir, xx) for xx in tmp_img_files])\n",
    "    time_vec.extend([ctime(os.path.join(pos_dir, xx)) for xx in tmp_img_files])\n",
    "    pos_vec.extend(len(tmp_img_files)*[pos_int])\n",
    "    frame_vec.extend([np.int(xx[4:13]) for xx in tmp_img_files])\n",
    "    channel_vec.extend([np.int(xx[14:15]) for xx in tmp_img_files])\n",
    "\n",
    "files_df = pd.DataFrame(dict(zip(['pos','frame','channel', 'fn', 'time'], [pos_vec, frame_vec, channel_vec, img_files, time_vec])))\n",
    "t_min = files_df.time.min()\n",
    "files_df.loc[:,'time'] = files_df.loc[:,'time'] - t_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '/mnt/disks/timelapse-movies/190108/data/20190108_1/img_000000024_0_000.tif',\n",
       "       '/mnt/disks/timelapse-movies/190108/data/20190108_again_1/img_000000048_5_000.tif',\n",
       "       '/mnt/disks/timelapse-movies/190108/data/20190108_1/img_000000007_3_000.tif',\n",
       "       '/mnt/disks/timelapse-movies/190108/data/20190108_1/img_000000046_3_000.tif',\n",
       "       '/mnt/disks/timelapse-movies/190108/data/20190108_1/img_000000005_5_000.tif',\n",
       "       '/mnt/disks/timelapse-movies/190108/data/20190108_1/img_000000049_5_000.tif',\n",
       "       '/mnt/disks/timelapse-movies/190108/data/20190108_again_1/img_000000047_5_000.tif',\n",
       "       '/mnt/disks/timelapse-movies/190108/data/20190108_1/img_000000031_3_000.tif',\n",
       "       '/mnt/disks/timelapse-movies/190108/data/20190108_again_1/img_000000040_5_000.tif',\n",
       "       '/mnt/disks/timelapse-movies/190108/data/20190109_postcheck_1/img_000000000_0_000.tif'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df.fn.sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_fdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-6ba140528fcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# [all_channel_dict[xx] for xx in chan_ind]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msorted_fdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_fdf' is not defined"
     ]
    }
   ],
   "source": [
    "# with skimage.external.tifffile.TiffFile('fullmovie_nomask.tif') as img:\n",
    "#     im_all = img.asarray(memmap=True)\n",
    "# print(im_all.shape)\n",
    "# # with skimage.external.tifffile.TiffFile('180711_fullmovie_masksonly.tif') as img:\n",
    "# #     im_masks = img.asarray(memmap=True)\n",
    "    \n",
    "# t_df = pd.read_csv('{}_time.csv'.format(nb_prefix))\n",
    "\n",
    "# print(all_metadata.keys())\n",
    "# [all_channel_dict[xx] for xx in chan_ind]\n",
    "\n",
    "sorted_fdf.iloc[10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sorted_fdf = files_df.sort_values(by=['frame', 'pos', 'channel'])\n",
    "# print(sorted_fdf)\n",
    "\n",
    "# quickly just sum all of the fluorescence channels\n",
    "\n",
    "def par_worker(fdf_sub, fn_out):\n",
    "    n_rows, _ = fdf_sub.shape\n",
    "    columns = ['pos', 'frame', 'channel', 'sum']\n",
    "    out_df = pd.DataFrame(np.zeros((n_rows, 4),dtype=np.int), columns=columns)\n",
    "    for i in range(n_rows):\n",
    "        pos, frame, channel, fn = fdf_sub.iloc[i,:]\n",
    "        im = skimage.io.imread(fn)\n",
    "        img_sum = im.sum().sum()\n",
    "        out_df.iloc[i,:] = np.array([pos, frame, channel, img_sum], dtype=np.int)\n",
    "    out_df.to_csv(fn_out, index=False)\n",
    "\n",
    "fdf_fluor = sorted_fdf.loc[sorted_fdf.channel > 0,:]\n",
    "fn_outs = [\"worker_outputs/par_output_{}.csv\".format(xx) for xx in range(4)]\n",
    "\n",
    "jobs = []\n",
    "for i in [0,1,2,3]:\n",
    "    p = multiprocessing.Process(target=par_worker, \n",
    "                                args=(fdf_fluor.iloc[i::4,:], fn_outs[i]))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "for j in jobs:\n",
    "    j.join()\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([pd.read_csv(fn) for fn in fn_outs])\n",
    "def strain_fn(xx):\n",
    "    if xx < 5:\n",
    "        return 0\n",
    "    if xx < 10:\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "\n",
    "def inducer_fn(xx):\n",
    "    if xx in [0,5,10]:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "strain_vec = [strain_fn(xx) for xx in all_data.pos.values]\n",
    "strain_series = pd.Series(strain_vec, index=all_data.index)\n",
    "\n",
    "indu_vec = [inducer_fn(xx) for xx in all_data.pos.values]\n",
    "indu_series = pd.Series(indu_vec, index=all_data.index)\n",
    "\n",
    "df = all_data.assign(strain=strain_series)\n",
    "df = df.assign(induced=indu_series)\n",
    "g = sns.lmplot(data=df, x='frame', hue='induced', y='sum', row='channel', fit_reg=False, sharey=False, col='strain')\n",
    "g.axes[0,0].set_title('RFP Strain 0')\n",
    "g.axes[0,1].set_title('RFP Strain 1')\n",
    "g.axes[0,2].set_title('RFP Strain 2')\n",
    "g.axes[1,0].set_title('CFP Strain 0')\n",
    "g.axes[1,1].set_title('CFP Strain 1')\n",
    "g.axes[1,2].set_title('CFP Strain 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract movie metadata\n",
    "all_metadata = fn_metadata_full(img_files[0])\n",
    "summ_dict = all_metadata['Summary']\n",
    "chan_ind = summ_dict['ChNames']\n",
    "chan_int = [int(xx) for xx in chan_ind]\n",
    "n_chan = len(chan_ind)\n",
    "chan_int_dict = dict(zip(chan_int, np.arange(n_chan)))\n",
    "chan_name = [all_channel_dict[xx] for xx in chan_ind]\n",
    "n_pos = summ_dict['Positions']\n",
    "n_frames = summ_dict['Frames']\n",
    "im_width = summ_dict['Width']\n",
    "im_height = summ_dict['Height']\n",
    "\n",
    "# Cor_pos_df is corrected position DF. In this notebook, correcting the position is not\n",
    "# necessary as there are only two imaging positions per pad. DF also includes inducer info\n",
    "# 0, 1, 2 for inducers blank, C, R; respectively\n",
    "cor_pos_df = pd.DataFrame(np.empty((n_pos,7)),\n",
    "                          columns=['x','y','label', 'pos', 'pad', 'strain', 'inducer'])\n",
    "for p_i in np.arange(n_pos):\n",
    "    x, y = summ_dict['InitialPositionList'][p_i]['DeviceCoordinatesUm']['XYStage']\n",
    "    label = summ_dict['InitialPositionList'][p_i]['Label']\n",
    "    cor_pos_df.loc[p_i,['x', 'y', 'label', 'pos']] = [x, y, label, p_i]\n",
    "\n",
    "# pad 0, C\n",
    "for pos in np.arange(2):\n",
    "    cor_pos_df.loc[pos,['pad', 'inducer']] = 0, 1\n",
    "    \n",
    "# pad 1, C\n",
    "for pos in np.arange(2,4):\n",
    "    cor_pos_df.loc[pos,['pad', 'inducer']] = 1, 1\n",
    "\n",
    "# pad 2, B\n",
    "cor_pos_df.loc[4,['pad', 'inducer']] = 2, 0\n",
    "\n",
    "# pad 3, C\n",
    "cor_pos_df.loc[5,['pad', 'inducer']] = 3, 1\n",
    "\n",
    "# pad 4, R\n",
    "for pos in np.arange(6,8):\n",
    "    cor_pos_df.loc[pos,['pad', 'inducer']] = 4, 2\n",
    "\n",
    "# pad 5, R\n",
    "cor_pos_df.loc[8,['pad', 'inducer']] = 5, 2\n",
    "    \n",
    "\n",
    "# Judging from the movie data, these are the strains at each position\n",
    "for pos in np.arange(n_pos):\n",
    "    if pos in [0,3,5,7,9,10]:\n",
    "        cor_pos_df.loc[pos, 'strain'] = 'pRC'\n",
    "    else:\n",
    "        cor_pos_df.loc[pos, 'strain'] = 'pCR'\n",
    "    \n",
    "def dist_f(pad_ind):\n",
    "    '''\n",
    "    Calculates distance between colonies for input pad index\n",
    "    '''\n",
    "    pos_arr = cor_pos_df.loc[cor_pos_df.pad == 3, ['x', 'y']].values\n",
    "    dist = np.sqrt(np.sum(np.power(np.diff(pos_arr, axis=0),2)))\n",
    "    return dist\n",
    "    \n",
    "plt.figure(figsize=(8,8))\n",
    "for p_i in np.arange(n_pos):\n",
    "    if cor_pos_df.loc[p_i, 'strain'] == 'pRC':\n",
    "        point_color='r'\n",
    "    else:\n",
    "        point_color = 'g'\n",
    "    plt.plot(np.float(cor_pos_df.x[p_i]), \n",
    "             -np.float(cor_pos_df.y[p_i]), \n",
    "             '.', \n",
    "             label=cor_pos_df.label[p_i],\n",
    "             ms=20)\n",
    "#              c=point_color)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape metadata\n",
    "\n",
    "def make_tdf():\n",
    "    template = \"/mnt/disks/timelapse-movies/180831/20180831_1/{}/img_{:09d}_0_000.tif\"\n",
    "    i = 0\n",
    "    t_skip = 1\n",
    "    t_points = np.arange(0,n_frames,t_skip)\n",
    "    t_len = len(t_points)\n",
    "    p_skip = 1\n",
    "    p_points = np.arange(0,n_pos,p_skip)\n",
    "    p_len = len(p_points)\n",
    "    t_df = pd.DataFrame(np.empty((n_frames*n_pos,3)), columns=['frame', 'pos', 'time'])\n",
    "    for p_i in p_points:\n",
    "        for t_i in t_points:\n",
    "            fn = template.format(cor_pos_df.loc[p_i,'label'], t_i)\n",
    "            t_df.loc[i,:] = np.array([t_i, p_i, ctime(fn)])\n",
    "            i += 1\n",
    "    t_df.to_csv('{}_time.csv'.format(nb_prefix), index=False)\n",
    "\n",
    "\n",
    "make_tdf()\n",
    "t_df = pd.read_csv('{}_time.csv'.format(nb_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a tiff image stack without a mask channel\n",
    "def make_movie(fn_out, t_skip=5, p_skip=1, files_df=files_df):\n",
    "    # I don't think this works but keep a metadata dictionary to store useful metatdata in \n",
    "    # the output video\n",
    "    keep_keys = ['Channel', 'Time', 'PositionName']\n",
    "    metadata = dict(zip(keep_keys, keep_keys))\n",
    "    # Set indices\n",
    "    i = 0\n",
    "    t_points = np.arange(0,n_frames,t_skip)\n",
    "    t_len = len(t_points)\n",
    "    p_points = np.arange(0,n_pos,p_skip)\n",
    "    p_len = len(p_points)\n",
    "    im_out = np.zeros((t_len,p_len,n_chan,im_height,im_width,1), dtype=np.uint16)\n",
    "    # Write movie to file\n",
    "    with TiffWriter(fn_out, imagej=True, append=False) as tif:\n",
    "        for tp in t_points:\n",
    "            for pp in p_points:\n",
    "                # position label is used to complete filename\n",
    "                # strain is used to determine which fluorescence channel to use for segmentation\n",
    "                pos_str = cor_pos_df.loc[pp, 'label']\n",
    "                for cp in chan_int:\n",
    "                    fn = file_temp.format(pos_str, tp, cp)\n",
    "                    eof_flag = True\n",
    "                    print(\"Writing \", fn)\n",
    "                    with Image.open(fn) as img:\n",
    "                        while eof_flag:\n",
    "                            _, _, im_arr = get_data_from_frame(img)\n",
    "                            if im_arr.shape[0] > 2000:\n",
    "                                im_arr = np.round(skimage.transform.downscale_local_mean(im_arr, (2,2)))\n",
    "                            im_arr = im_arr.astype(np.float32).astype(np.uint16)\n",
    "                            img_md = img_metadata_dict_full(img)\n",
    "                            for k in keep_keys:\n",
    "                                metadata[k] = img_md[k]\n",
    "                            h, w = im_arr.shape\n",
    "                            im_out[tp//t_skip, pp//p_skip, chan_int_dict[cp], :, :, 0] = im_arr\n",
    "                            try:\n",
    "                                i += 1\n",
    "                                img.seek(img.tell()+1)\n",
    "                            except:\n",
    "                                eof_flag = False\n",
    "        tif.save(im_out, metadata=metadata.copy())\n",
    "\n",
    "# make_movie('fullmovie_nomask.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a tiff image stack with a mask channel\n",
    "def make_movie(fn_out, t_skip=10, p_skip=1, n_pos=n_pos,n_frames=n_frames):\n",
    "    # I don't think this works but keep a metadata dictionary to store useful metatdata in \n",
    "    # the output video\n",
    "    keep_keys = ['Channel', 'Time', 'PositionName']\n",
    "    metadata = dict(zip(keep_keys, keep_keys))\n",
    "    # Set indices\n",
    "    i = 0\n",
    "    t_points = np.arange(0,n_frames,t_skip)\n",
    "    t_len = len(t_points)\n",
    "    p_points = np.arange(0,n_pos,p_skip)\n",
    "    p_len = len(p_points)\n",
    "    im_out = np.zeros((t_len,p_len,n_chan+1,im_height,im_width,1), dtype=np.uint16)\n",
    "    # Write movie to file\n",
    "    with TiffWriter(fn_out, imagej=True, append=False) as tif:\n",
    "        for tp in t_points:\n",
    "            for pp in p_points:\n",
    "                # position label is used to complete filename\n",
    "                # strain is used to determine which fluorescence channel to use for segmentation\n",
    "                pos_str, strain = cor_pos_df.loc[pp, ['label', 'strain']]\n",
    "                if strain == 'pCR':\n",
    "                    segment_channel = 1 # gfp channel\n",
    "                else:\n",
    "                    segment_channel = 2 # rfp channel\n",
    "                for cp in chan_int:\n",
    "                    pos_str = cor_pos_df.loc[pp, 'label']\n",
    "                    fn = file_temp.format(pos_str, tp, cp)\n",
    "                    eof_flag = True\n",
    "                    print(\"Writing \", fn)\n",
    "                    with Image.open(fn) as img:\n",
    "                        while eof_flag:\n",
    "                            # Get image array\n",
    "                            _, _, im_arr = get_data_from_frame(img)\n",
    "                            # Label image\n",
    "                            if cp == segment_channel:\n",
    "                                im_lab, col_num = label_image(im_arr)\n",
    "                                im_out[tp//t_skip, pp//p_skip, n_chan, :, :, 0] = im_lab.astype(np.uint16)\n",
    "                            # Downscale if image width is more than 2000 pixels\n",
    "                            if im_arr.shape[0] > 2000:\n",
    "                                im_arr = np.round(skimage.transform.downscale_local_mean(im_arr, (2,2)))\n",
    "                            im_arr = im_arr.astype(np.float32).astype(np.uint16)\n",
    "                            # I'm not sure this works but keep image metadata for the current frame\n",
    "                            img_md = img_metadata_dict_full(img)\n",
    "                            for k in keep_keys:\n",
    "                                metadata[k] = img_md[k]\n",
    "                            h, w = im_arr.shape\n",
    "                            im_out[tp//t_skip, pp//p_skip, chan_int_dict[cp], :, :, 0] = im_arr\n",
    "                            try:\n",
    "                                i += 1\n",
    "                                img.seek(img.tell()+1)\n",
    "                            except:\n",
    "                                eof_flag = False\n",
    "        tif.save(im_out, metadata=metadata.copy())\n",
    "\n",
    "# make_movie('fullmovie_mask.tif', n_frames=80, n_pos=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as anm\n",
    "from IPython.display import HTML\n",
    "\n",
    "# img = skimage.io.imread(f_names[2])\n",
    "def write_movie(img, skip=10, pos=3):\n",
    "    plt.close('all')\n",
    "    \n",
    "    t_points, s, c, h, w = img.shape\n",
    "    t_vec = np.arange(0, t_points, skip)\n",
    "    frames = len(t_vec)\n",
    "    #t_list = list(t_vec[-1::-1]) + [-1]\n",
    "    \n",
    "    t_list = np.arange(t_points)\n",
    "    \n",
    "    blank_array = np.zeros([h, w])\n",
    "    fig, axs = plt.subplots(2,2, figsize=(10,8))\n",
    "    im_list = [0,0,0,0]\n",
    "    \n",
    "    # initialize plots\n",
    "    titles = ['bf', 'gfp', 'mscarlet', 'lab']\n",
    "    vmaxs = [2.8e4  , 1e4, 1e4, 1]\n",
    "    vmins = [1e4, 1e3, 1e3, 0]\n",
    "    for i in np.arange(3):\n",
    "        ax = axs[i//2, np.mod(i,2)]\n",
    "        indxs = [i]\n",
    "        vmax = vmaxs[i]\n",
    "        vmin = vmins[i]\n",
    "        im = ax.imshow(blank_array, animated=True, vmax=vmax, vmin=vmin, interpolation='none')\n",
    "        cbar = fig.colorbar(im, ax=ax, ticks=[vmin, vmax])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(titles[i])\n",
    "        im_list[i] = im\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # animation function.  This is called sequentially\n",
    "    frame_arr = np.zeros((h,w))\n",
    "    def animate(i):\n",
    "        # Plot \n",
    "        for j in np.arange(3):\n",
    "            ax = axs[j//2, np.mod(j,2)]\n",
    "            frame_arr = img[i*skip,pos,j,:,:]#.sum(axis=0)\n",
    "            im_list[j].set_array(frame_arr)\n",
    "\n",
    "    # call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "#     writer = anm.HTMLWriter()\n",
    "    anim = anm.FuncAnimation(fig, animate, interval=100, frames=frames)\n",
    "\n",
    "\n",
    "    # Set up formatting for the movie files\n",
    "    #Writer = anm.writers['ffmpeg_file']\n",
    "    #writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=900, extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "    # save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "    # installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "    # the video can be embedded in html5.  You may need to adjust this for\n",
    "    # your system: for more information, see\n",
    "    # http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "    #anim.save('animation_{}.mp4'.format(fn), extra_args=['-vcodec', 'libx264'], dpi=50, writer=writer)\n",
    "    #plt.close('all')\n",
    "\n",
    "\n",
    "    #anim.save('animation_{}.mp4'.format(fn), writer=writer)\n",
    "    plt.close('all')\n",
    "    return anim\n",
    "    #HTML(anim.to_html5_video())\n",
    "    \n",
    "\n",
    "# with skimage.external.tifffile.TiffFile('180320_fullmovie_masktry.tif') as img:\n",
    "#     im_all = img.asarray()\n",
    "anim = write_movie(im_all, skip=1, pos=7)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anim.to_html5_video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t, s, c, h, w = im_all.shape\n",
    "im_out = np.zeros((t,3,h,5*w), dtype=np.float32)\n",
    "\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "blank_array = np.zeros([h, 5*w, 3])\n",
    "gray_array = np.ones([h, w, 3])\n",
    "red_array = np.zeros([h, w, 3])\n",
    "red_array[:,:,0] = np.ones([h, w])\n",
    "red_array[:,:,1] = np.ones([h, w]) * 0\n",
    "red_array[:,:,2] = np.ones([h, w]) * 0.\n",
    "cyan_array = np.zeros([h, w, 3])\n",
    "cyan_array[:,:,0] = np.ones([h, w]) * 0\n",
    "cyan_array[:,:,1] = np.ones([h, w]) \n",
    "cyan_array[:,:,2] = np.ones([h, w])\n",
    "i=70\n",
    "# Plot cell densities\n",
    "min_v = [10e3, 100, 100]\n",
    "max_v = [30e3, 500, 500]\n",
    "plt.figure(figsize=(15,3))\n",
    "# Plot cell densities\n",
    "frame = np.zeros([h, 5*w, 3])\n",
    "for c, c_array in enumerate([gray_array, red_array, cyan_array]):\n",
    "    for p, p_i in enumerate([5,4,3]):\n",
    "        d_arr = (im_all[i,p_i,c,:,:] - min_v[c]) / (max_v[c] - min_v[c])\n",
    "#         d_arr[d_arr > 1 ] = 1\n",
    "#         d_arr[d_arr < 0 ] = 0\n",
    "        frame[:,(2*w*p):(2*w*(1+p)-w),:] += c_array * np.stack(3*[d_arr], axis=2)\n",
    "frame[frame > 1 ] = 1\n",
    "frame[frame < 0 ] = 0\n",
    "plt.imshow(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with skimage.external.tifffile.TiffFile('mask_images/mask_44_13.tif') as img:\n",
    "    im_mask = img.asarray(memmap=True)\n",
    "_ = plt.imshow(im_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#  Use masks to track fluorescence of microcolonies\n",
    "#\n",
    "\n",
    "import matplotlib.animation as anm\n",
    "from IPython.display import HTML\n",
    "\n",
    "def par_worker(im_arr, t_df, fn_out):\n",
    "    img_temp = \"mask_images/mask_{:02d}_{:1d}.tif\"\n",
    "    column_names = ('frame','time', 'pos', 'colony', 'sfcfp', 'mscarlet', 'col_size', 'sfcfp_bg', 'mscarlet_bg')\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "    t, s, _, h, w = im_arr.shape\n",
    "    t_df_piv = t_df.pivot('frame', 'pos', 'time')\n",
    "    for t_i in range(0,t,1):\n",
    "        i_frame = t_df.index[t_i]\n",
    "        for s_i in range(s):\n",
    "            ct = t_df_piv.loc[i_frame, s_i]\n",
    "#             im_labeled, num = label_image_2(im_arr[t_i, s_i, 1:2,:,:].sum(axis=0))\n",
    "            rfps, gfps, sizes, num, gfp_bg, rfp_bg, im_labeled = get_fluors_2(im_arr[t_i,s_i,1,:,:], \n",
    "                                                                              im_arr[t_i,s_i,2,:,:])\n",
    "            img_fn = img_temp.format(i_frame, s_i)\n",
    "            skimage.io.imsave(img_fn, im_labeled.astype(np.uint8))\n",
    "#             for col_i in range(num):\n",
    "#                 df_dict = dict(zip(column_names, [[i_frame],[ct], [s_i], [col_i], [gfps[col_i]], [rfps[col_i]], [sizes[col_i]], [gfp_bg], [rfp_bg]]))\n",
    "#                 df = df.append(pd.DataFrame(df_dict), ignore_index=True)\n",
    "#     df.to_csv(fn_out)\n",
    "    print(\"wrote \", fn_out)\n",
    "\n",
    "fn_temp = \"processed_part_masktry_{}.csv\"\n",
    "fn_outs = [fn_temp.format(i) for i in range(4)]\n",
    "\n",
    "jobs = []\n",
    "for i in [0,1,2,3]:\n",
    "    p = multiprocessing.Process(target=par_worker, \n",
    "                                args=(im_all[i::4,:,:,:,:], \n",
    "                                t_df.loc[i::4,:], fn_outs[i]))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "for j in jobs:\n",
    "    j.join()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Simply take means of the full field of view\n",
    "#\n",
    "\n",
    "def par_worker(im_arr, t_vec, fn_out):\n",
    "    column_names = ('time', 'pos', 'sfcfp', 'mscarlet')\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "    t, s, _, h, w = im_arr.shape\n",
    "    for t_i in range(0,t,1):\n",
    "        for s_i in range(s):\n",
    "            ct = t_vec[t_i]\n",
    "            df_dict = dict(zip(column_names, [[ct], [s_i], [im_arr[t_i,s_i,2,:,:].mean()], [im_arr[t_i,s_i,1,:,:].mean()]]))\n",
    "            df = df.append(pd.DataFrame(df_dict), ignore_index=True)\n",
    "    df.to_csv(fn_out)\n",
    "    print(\"wrote \", fn_out)\n",
    "\n",
    "# t_df = pd.read_csv('time.csv', index_col=None)\n",
    "t_piv = t_df.pivot('frame', 'pos', 'time')\n",
    "fn_temp = \"full_image_part_2_{}.csv\"\n",
    "fn_outs = [fn_temp.format(i) for i in range(4)]\n",
    "\n",
    "jobs = []\n",
    "for i in [0,1,2,3]:\n",
    "    p = multiprocessing.Process(target=par_worker, \n",
    "                                args=(im_all[i::4,:,:,:,:], \n",
    "                                t_piv.values[i::4,0], fn_outs[i]))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "for j in jobs:\n",
    "    j.join()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = 'processed_part_masktry_{}.csv'\n",
    "column_names = ('time', 'pos', 'colony', 'sfcfp', 'mscarlet', 'col_size', 'sfcfp_bg', 'mscarlet_bg')\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "for fn in [temp.format(i) for i in range(4)]:\n",
    "    df = df.append(pd.read_csv(fn, dtype=np.float), ignore_index=True)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = 'processed_part_masktry_{}.csv'\n",
    "column_names = ('time', 'pos', 'colony', 'sfcfp', 'mscarlet', 'col_size', 'sfcfp_bg', 'mscarlet_bg')\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "for fn in [temp.format(i) for i in range(4)]:\n",
    "    df = df.append(pd.read_csv(fn), ignore_index=True)\n",
    "t_df_piv = t_df.pivot('frame', 'pos', 'time')\n",
    "for i in np.arange(df.shape[0]):\n",
    "    i_frame, i_pos = df.loc[i, [\"frame\",\"pos\"]]\n",
    "    df.loc[i,'time'] = t_df_piv.loc[np.int(i_frame), i_pos]\n",
    "df.to_csv('{}_masktry_df_2.csv'.format(nb_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('{}_masktry_df.csv'.format(nb_prefix))\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,4))\n",
    "t_min = df.time.min()\n",
    "ind = (df.pos == 4) & (df.colony>1) & (df.colony<10) # & (np.mod(df.colony,  5)==0 )\n",
    "df_tmp = df.loc[ind,:]\n",
    "# ax.plot((df_tmp.time - t_min)/3600, df_tmp.mscarlet,'r.')\n",
    "# ax.plot((df_tmp.time - t_min)/3600, df_tmp.sfcfp,'c.')\n",
    "ax.scatter(x=(df_tmp.time - t_min)/3600, \n",
    "           y=df_tmp.col_size,\n",
    "           alpha=1, cmap='viridis')\n",
    "new_t_vec = np.sort(np.unique(df_tmp.time - t_min))\n",
    "r_c = (7e-3)/60\n",
    "for i in np.arange(50,210,50):\n",
    "    ax.plot(new_t_vec/3600, i*np.exp(new_t_vec*r_c),'k-')\n",
    "# ax.set_facecolor('gray')\n",
    "ax.set_ylim([-1e1,200])\n",
    "ax.set_yticks(np.arange(0,601,200))\n",
    "ax.set_ylabel('Colony area (pixels)')\n",
    "ax.set_xlabel('Time (hours)')\n",
    "ax.set_xticks(np.arange(0,4,1))\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"microscope_cellgrowth.png\", dpi=150, transparent=True)\n",
    "fig.savefig(\"microscope_cellgrowth.pdf\")\n",
    "# fig, ax = plt.subplots(1,1,figsize=(9,9))\n",
    "# # ind = (df.time < (6*60*60 + t_min)) & (df.pos == 3)\n",
    "# # df_tmp = df.loc[ind,:]\n",
    "to_full_screen = np.log((1024**2)/67057)/r_c\n",
    "print(to_full_screen / 3600)\n",
    "print((df.time.max() - t_min)/3600)\n",
    "print(df.loc[(df.time == t_min)&(df.pos == 4), 'col_size'].sum())\n",
    "print((df.loc[(df.time == t_min)&(df.pos == 4), 'col_size'].sum())/(1024**2))\n",
    "# ax.scatter(x=df_tmp.mscarlet, \n",
    "#            y=df_tmp.sfcfp,\n",
    "#            c=df_tmp.time,alpha=0.3, cmap='viridis')\n",
    "# ax.set_facecolor('gray')\n",
    "# (df_tmp.time[df_tmp.sfcfp > 200].min() - df_tmp.time[df_tmp.mscarlet > 200].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,4))\n",
    "t_min = df.time.min()\n",
    "ind = np.isclose(df.pos.astype(np.int), 21)\n",
    "df_tmp = df.loc[ind,:]\n",
    "# ax.plot((df_tmp.time - t_min)/3600, df_tmp.mscarlet,'r.')\n",
    "# ax.plot((df_tmp.time - t_min)/3600, df_tmp.sfcfp,'c.')\n",
    "ax.scatter(x=(df_tmp.time - t_min)/3600, \n",
    "           y=df_tmp.mscarlet,#/ \n",
    "#            c=df_tmp.mscarlet,\n",
    "           alpha=1)#, cmap='viridis')\n",
    "ax.set_ylim([0,1.5e3])\n",
    "new_t_vec = np.sort(np.unique(df_tmp.time - t_min))\n",
    "r_c = (7e-3)/60\n",
    "# for i in np.arange(50,210,50):\n",
    "#     ax.plot(new_t_vec/3600, i*np.exp(new_t_vec*r_c),'k-')\n",
    "# ax.set_facecolor('gray')\n",
    "# ax.set_ylim([600,800])\n",
    "\n",
    "# ax.set_yticks(np.arange(0,601,200))\n",
    "ax.set_ylabel('Colony area (pixels)')\n",
    "ax.set_xlabel('Time (hours)')\n",
    "# ax.set_xticks(np.arange(4,8,1))\n",
    "# ax.set_xlim([0,800])\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"microscope_cellgrowth.png\", dpi=150, transparent=True)\n",
    "# fig.savefig(\"microscope_cellgrowth.pdf\")\n",
    "# fig, ax = plt.subplots(1,1,figsize=(9,9))\n",
    "# # ind = (df.time < (6*60*60 + t_min)) & (df.pos == 3)\n",
    "# # df_tmp = df.loc[ind,:]\n",
    "to_full_screen = np.log((1024**2)/67057)/r_c\n",
    "print(to_full_screen / 3600)\n",
    "print((df.time.max() - t_min)/3600)\n",
    "print(df.loc[(df.time == t_min)&(df.pos == 4), 'col_size'].sum())\n",
    "print((df.loc[(df.time == t_min)&(df.pos == 4), 'col_size'].sum())/(1024**2))\n",
    "# ax.scatter(x=df_tmp.mscarlet, \n",
    "#            y=df_tmp.sfcfp,\n",
    "#            c=df_tmp.time,alpha=0.3, cmap='viridis')\n",
    "# ax.set_facecolor('gray')\n",
    "# (df_tmp.time[df_tmp.sfcfp > 200].min() - df_tmp.time[df_tmp.mscarlet > 200].min())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
